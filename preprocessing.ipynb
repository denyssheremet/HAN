{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6f91d0-f394-42f9-b79f-f3d028f9ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from my_utils import save_to_pickle, load_from_pickle\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62238499-8bde-4460-b278-21edb48dfa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7e666937cb3173ed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-7e666937cb3173ed/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d52c22705a43bdafe66343d5cad737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297cbdeffde74ab18fb3a506927d9b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-7e666937cb3173ed/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b785a727281e45bf8ade6096a4b4eaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['link', 'headline', 'category', 'short_description', 'authors', 'date'],\n",
       "    num_rows: 209527\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"data/News_Category_Dataset_v3.json\", split=[\"train\"])[0]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466f31d9-3b43-4b4c-9eed-d28944f56338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['link', 'headline', 'category', 'short_description', 'authors', 'date'],\n",
      "    num_rows: 125715\n",
      "})\n",
      "Dataset({\n",
      "    features: ['link', 'headline', 'category', 'short_description', 'authors', 'date'],\n",
      "    num_rows: 41906\n",
      "})\n",
      "Dataset({\n",
      "    features: ['link', 'headline', 'category', 'short_description', 'authors', 'date'],\n",
      "    num_rows: 41906\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ds1 = dataset.train_test_split(0.2, seed=42)\n",
    "ds2 = ds1['train'].train_test_split(0.25, seed=42)\n",
    "ds_train = ds2['train']\n",
    "ds_val = ds2['test']\n",
    "ds_test = ds1['test']\n",
    "\n",
    "print(ds_train)\n",
    "print(ds_val)\n",
    "print(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3162881c-693c-4fef-a7d5-72f516a6186f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link': 'https://www.huffingtonpost.com/entry/nicki-minaj-soulja-boy-yasss-bish_n_5260517.html',\n",
       " 'headline': 'Nicki Minaj Addresses Donald Sterling Controversy In New Song',\n",
       " 'category': 'ENTERTAINMENT',\n",
       " 'short_description': '',\n",
       " 'authors': 'Matthew Jacobs',\n",
       " 'date': datetime.datetime(2014, 5, 3, 0, 0)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e73577f-06da-4400-80a2-240b9a596ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WELLNESS', 'GOOD NEWS', 'TASTE', 'IMPACT', 'ENTERTAINMENT', 'TRAVEL', 'TECH', 'PARENTING', 'WORLDPOST', 'U.S. NEWS', 'CRIME', 'HEALTHY LIVING', 'HOME & LIVING', 'SCIENCE', 'BLACK VOICES', 'EDUCATION', 'GREEN', 'WORLD NEWS', 'ENVIRONMENT', 'POLITICS', 'QUEER VOICES', 'WEIRD NEWS', 'PARENTS', 'STYLE', 'ARTS', 'BUSINESS', 'FIFTY', 'COLLEGE', 'ARTS & CULTURE', 'SPORTS', 'CULTURE & ARTS', 'THE WORLDPOST', 'MEDIA', 'DIVORCE', 'STYLE & BEAUTY', 'FOOD & DRINK', 'RELIGION', 'MONEY', 'COMEDY', 'WOMEN', 'WEDDINGS', 'LATINO VOICES'}\n"
     ]
    }
   ],
   "source": [
    "categories = set(dataset['category'])\n",
    "print(categories)\n",
    "category_map = dict(zip(categories, range(len(categories))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8fb4524-3e1c-45cd-b6ab-11278fca8ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the amount of articles per category\n",
    "# categories = set(dataset['category'])\n",
    "# cat_count = {cat: dataset['category'].count(cat) for cat in categories}\n",
    "# cat_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac81c1-afa3-421f-b877-81fbee722066",
   "metadata": {
    "tags": []
   },
   "source": [
    "{'FIFTY': 1401,\n",
    " 'GREEN': 2622,\n",
    " 'BLACK VOICES': 4583,\n",
    " 'MONEY': 1756,\n",
    " 'LATINO VOICES': 1130,\n",
    " 'STYLE & BEAUTY': 9814,\n",
    " 'TECH': 2104,\n",
    " 'COLLEGE': 1144,\n",
    " 'THE WORLDPOST': 3664,\n",
    " 'WELLNESS': 17945,\n",
    " 'WORLD NEWS': 3299,\n",
    " 'ARTS & CULTURE': 1339,\n",
    " 'COMEDY': 5400,\n",
    " 'TRAVEL': 9900,\n",
    " 'WORLDPOST': 2579,\n",
    " 'ARTS': 1509,\n",
    " 'DIVORCE': 3426,\n",
    " 'WEDDINGS': 3653,\n",
    " 'RELIGION': 2577,\n",
    " 'FOOD & DRINK': 6340,\n",
    " 'SCIENCE': 2206,\n",
    " 'WEIRD NEWS': 2777,\n",
    " 'CRIME': 3562,\n",
    " 'PARENTING': 8791,\n",
    " 'BUSINESS': 5992,\n",
    " 'WOMEN': 3572,\n",
    " 'STYLE': 2254,\n",
    " 'ENTERTAINMENT': 17362,\n",
    " 'HEALTHY LIVING': 6694,\n",
    " 'EDUCATION': 1014,\n",
    " 'QUEER VOICES': 6347,\n",
    " 'U.S. NEWS': 1377,\n",
    " 'TASTE': 2096,\n",
    " 'SPORTS': 5077,\n",
    " 'ENVIRONMENT': 1444,\n",
    " 'PARENTS': 3955,\n",
    " 'POLITICS': 35602,\n",
    " 'HOME & LIVING': 4320,\n",
    " 'GOOD NEWS': 1398,\n",
    " 'MEDIA': 2944,\n",
    " 'CULTURE & ARTS': 1074,\n",
    " 'IMPACT': 3484}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7796639-2867-4987-9bbc-de60aec3c18c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d48faa7-64ea-4d4e-af66-183e25bb5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        # lowercase, remove punctuation, and split by space\n",
    "        out = text.lower().replace(\"\\n\",\"\").replace('t','').translate(str.maketrans('', '', string.punctuation)).split(\" \")\n",
    "        res = []\n",
    "        for i, word in enumerate(out):\n",
    "            if (any(char.isnumeric() for char in word)):\n",
    "                for letter in word:\n",
    "                    res.append(letter)\n",
    "            else:\n",
    "                res.append(word)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95355f0-c08f-4cc6-baa1-2e3a341da6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unil', 'you', 'have', 'a', 'dog', 'y', 'o', 'u', '1', 'don', 'undersand', 'wha', 'could', 'be', 'eaen']\n"
     ]
    }
   ],
   "source": [
    "sentence = '\"Until you have a dog you1 don\\'t understand\\n what could be eaten.\"'\n",
    "tokenizer = MyTokenizer()\n",
    "print(tokenizer(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "863ff174-ab42-49f1-8a5c-39c2526f9bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119119\n",
      "119119\n"
     ]
    }
   ],
   "source": [
    "# find all words in the text\n",
    "def find_all_tokens(dataset, tokenizer):\n",
    "    try: all_tokens = load_from_pickle(\"pickle/all_tokens.pickle\")\n",
    "    except:\n",
    "        all_tokens = set()\n",
    "        for d in [dataset['headline'], dataset['short_description']]:\n",
    "            for sentence in tqdm(d):\n",
    "                for token in tokenizer(sentence):\n",
    "                    all_tokens.add(token)\n",
    "        all_tokens = list(all_tokens)\n",
    "        all_tokens.sort()\n",
    "        save_to_pickle(all_tokens, \"pickle/all_tokens.pickle\")\n",
    "    return all_tokens\n",
    "\n",
    "def calc_token_counts(dataset, tokenizer):\n",
    "    try: token_counts = load_from_pickle(\"pickle/token_counts.pickle\")\n",
    "    except:\n",
    "        token_counts = OrderedDict()\n",
    "        for d in [dataset['headline'], dataset['short_description']]:\n",
    "            for sentence in tqdm(d):\n",
    "                for token in tokenizer(sentence):\n",
    "                    if token in token_counts.keys():\n",
    "                        token_counts[token] += 1\n",
    "                    else:\n",
    "                        token_counts[token] = 1\n",
    "        save_to_pickle(token_counts, \"pickle/token_counts.pickle\")\n",
    "    return token_counts\n",
    "\n",
    "\n",
    "            \n",
    "all_tokens = find_all_tokens(dataset, tokenizer)\n",
    "token_counts = calc_token_counts(dataset, tokenizer)\n",
    "print(len(all_tokens))\n",
    "print(len(token_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdf4745b-b099-45bc-b66a-239549da90e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 2104, 1253, 14115, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the vocab\n",
    "unk_token = '<unk>'\n",
    "vocab = torchtext.vocab.vocab(\n",
    "    token_counts,\n",
    "    min_freq=10,\n",
    "    specials=[unk_token], \n",
    "    special_first=True\n",
    ")\n",
    "vocab.set_default_index(vocab[unk_token])\n",
    "\n",
    "print(len(vocab))\n",
    "vocab[unk_token], vocab['hi'], vocab['dog'], vocab['dawg'], vocab['doggo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dba050ba-491c-41fc-86a4-d7d8eb90333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, a dataloader:\n",
    "\n",
    "def collate_fn(data):\n",
    "    # return list(map(lambda x: (x['headline'], x['short_description'], x['category']), data))\n",
    "    batch = {'headline': [], 'short_description': []}\n",
    "    targ = []\n",
    "    for item in data:\n",
    "        batch['headline'].append(item['headline'])\n",
    "        batch['short_description'].append(item['short_description'])\n",
    "        targ.append(item['category'])\n",
    "    targ = torch.tensor(list(map(lambda x: category_map[x], targ)), dtype=torch.int64)\n",
    "    return batch, targ\n",
    "\n",
    "micro_loader = DataLoader(ds_train.select(range(64)), collate_fn=collate_fn, batch_size=64, shuffle=True)\n",
    "train_loader = DataLoader(ds_train, collate_fn=collate_fn, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(ds_val, collate_fn=collate_fn, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(ds_test, collate_fn=collate_fn, batch_size=64, shuffle=True)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ef346f8-ff31-4ec0-a154-c6b3489a426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingModule(nn.Module):\n",
    "    def __init__(self, tokenizer, vocab):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def forward(self, x):\n",
    "        headlines, descriptions = x['headline'], x['short_description']\n",
    "        h_tok, d_tok = [], []\n",
    "        h_longest, d_longest = 0, 0\n",
    "        bs = len(headlines)\n",
    "        \n",
    "        for i in range(bs):\n",
    "            h_tok.append(self.vocab(self.tokenizer(headlines[i])))      \n",
    "            d_tok.append(self.vocab(self.tokenizer(descriptions[i])))\n",
    "            h_longest = max(h_longest, len(h_tok[-1]))\n",
    "            d_longest = max(d_longest, len(d_tok[-1]))\n",
    "        h_ten, d_ten = torch.zeros((bs,h_longest), dtype=torch.int32), torch.zeros((bs,d_longest), dtype=torch.int32)\n",
    "                \n",
    "        for i in range(bs):\n",
    "            h_ten[i,0:len(h_tok[i])] = torch.tensor(h_tok[i], dtype=torch.int32)\n",
    "            d_ten[i,0:len(d_tok[i])] = torch.tensor(d_tok[i], dtype=torch.int32)\n",
    "        return h_ten.cuda(), d_ten.cuda()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f932f86-a329-45dc-a6f9-b75b1ac5ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom embedding module - we'll have to train the embeddings\n",
    "\n",
    "# for embedding both the headline and description\n",
    "class EmbedItemModule(nn.Module):\n",
    "    def __init__(self, tokenizer, vocab, dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_ten, d_ten = x\n",
    "        emb_h = self.embedding(h_ten)\n",
    "        emb_d = self.embedding(d_ten)\n",
    "        return emb_h, emb_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "713233a3-46d3-4152-adb6-805d397e81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the baseline encoder, we just take the mean of the elements\n",
    "class BaselineEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb_h, emb_d = x\n",
    "        u, v = emb_h.mean(axis=1), emb_d.mean(axis=1)\n",
    "        return torch.hstack([u,v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a37de7b0-56e0-4d16-948e-246ba179fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_in, d_hid, d_out):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(d_in, d_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_hid, d_out),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "67216880-6304-41cd-9922-b3ed79d0aa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 42])\n"
     ]
    }
   ],
   "source": [
    "def make_baseline_model(embedding_dim, mlp_dim):\n",
    "    return nn.Sequential(\n",
    "        PreprocessingModule(tokenizer, vocab),\n",
    "        EmbedItemModule(tokenizer, vocab, embedding_dim).cuda(),\n",
    "        BaselineEncoder().cuda(),\n",
    "        MLP(2*embedding_dim, mlp_dim, len(categories)).cuda(),\n",
    "    )\n",
    "\n",
    "embedding_dim = 100\n",
    "model = make_baseline_model(embedding_dim, 200)\n",
    "\n",
    "for batch, targ in train_loader:\n",
    "    print(model(batch).shape)\n",
    "    # print(targ)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe2af545-334d-4ef7-8c93-4b7dbb80f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the training and evaluation loops\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0., 0.\n",
    "    bs = loader.batch_size\n",
    "    for batch, targ in loader:\n",
    "        # the tensors get moved to cuda at the end of the Preprocessing module\n",
    "        # note to self: next time I should preprocess the dataset once in advance instead of doing it every time on the fly\n",
    "        with torch.no_grad():\n",
    "            logits = model(batch)\n",
    "        preds = logits.detach().argmax(axis=1)\n",
    "        correct += (preds == targ.cuda()).sum()\n",
    "        total += bs\n",
    "    return correct / total     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "039506f3-1990-4619-8820-423124e65f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time()\n",
    "# evaluate(model, val_loader)\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "220d0675-03ea-40bc-9ce6-e9808890566b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023809523809523808"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bab9b1d3-deb5-4056-8e39-ec53a26d6365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41906"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7407f2f7-8186-4989-9db8-14a82ea9eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training \n",
    "def train_epoch(model, loader, optimizer, loss_module):\n",
    "    model.train()\n",
    "    for batch, targ in loader:\n",
    "        logits = model(batch)\n",
    "        loss = loss_module(logits, targ.cuda())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def train_model(model, train_loader, val_loader, optimizer, loss_module, epochs):\n",
    "    val_accs = []\n",
    "    for epoch in range(epochs):\n",
    "        train_epoch(model, train_loader, optimizer, loss_module)\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        val_accs.append(val_acc)\n",
    "        print(val_acc)\n",
    "    return val_accs\n",
    "\n",
    "def train_model_dev(model, train_loader, val_loader, optimizer, loss_module, epochs):\n",
    "    val_accs = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for i in range(1000):\n",
    "            train_epoch(model, train_loader, optimizer, loss_module)\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        val_accs.append(val_acc)\n",
    "        print(val_acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f240b7e7-c01d-4514-8304-88d883f01868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:20<04:53, 20.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9062, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:43<04:41, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9219, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [01:03<04:11, 20.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9375, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [01:25<03:55, 21.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9375, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [01:47<03:36, 21.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9688, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [02:07<03:11, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9688, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [02:28<02:49, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9688, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [02:48<02:23, 20.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9688, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [03:08<02:02, 20.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9688, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [03:30<01:44, 21.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [03:52<01:25, 21.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [04:14<01:04, 21.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [04:35<00:42, 21.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [04:56<00:21, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:17<00:00, 21.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = make_baseline_model(100,1000)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "loss_module = nn.CrossEntropyLoss()\n",
    "\n",
    "train_model_dev(model, micro_loader, micro_loader, optimizer, loss_module, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2208b36-f1ec-4bfb-86ae-6989bd794b94",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "I can overfit on one batch now, but it is way too slow. I'll try again, but this time making the dataloaders more efficient and see if it works better then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543108c0-2ffa-43b3-9a57-acfec6086c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
